{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from https://github.com/nsadawi/Download-Large-File-From-Google-Drive-Using-Python\n",
    "import requests\n",
    "import os\n",
    "\n",
    "def download_file_from_google_drive(id, destination):\n",
    "    URL = \"https://docs.google.com/uc?export=download\"\n",
    "\n",
    "    session = requests.Session()\n",
    "\n",
    "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
    "    token = get_confirm_token(response)\n",
    "\n",
    "    if token:\n",
    "        params = { 'id' : id, 'confirm' : token }\n",
    "        response = session.get(URL, params = params, stream = True)\n",
    "\n",
    "    save_response_content(response, destination)    \n",
    "\n",
    "def get_confirm_token(response):\n",
    "    for key, value in response.cookies.items():\n",
    "        if key.startswith('download_warning'):\n",
    "            return value\n",
    "\n",
    "    return None\n",
    "\n",
    "def save_response_content(response, destination):\n",
    "    CHUNK_SIZE = 32768\n",
    "\n",
    "    with open(destination, \"wb\") as f:\n",
    "        for chunk in response.iter_content(CHUNK_SIZE):\n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                f.write(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download training data\n",
    "file_id = '1LKMFgmRP0Il0fBRpfzNAIQVZgUDov8nK'\n",
    "destination = './data/train_data.pkl'\n",
    "if os.path.exists(destination) == False:    #destination が存在していない場合のみDL\n",
    "  download_file_from_google_drive(file_id, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:root:*** Initializing ***\n",
      "INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/cl-tohoku/bert-base-japanese-whole-word-masking/vocab.txt from cache at /Users/takizawa/.cache/torch/transformers/72ee6ecba54b20bba483760db4f23b836f27a6afda54ede38c488e8514bb3705.5fac9da4d8565963664ed9744688dc7008ff5ec4045f604e9515896f9fe46d9c\n",
      "INFO:root:Preparing training data\n",
      "INFO:root:Define Models\n",
      "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/cl-tohoku/bert-base-japanese-whole-word-masking/config.json from cache at /Users/takizawa/.cache/torch/transformers/c96f5e731b9f4dc2e8263336947ec74b6f93917c0b9db6e9cf974a8a945dd313.48bc8d0b377948cc990335b8cccbcce084039c1b792bea3d0da671abfc6a3fe5\n",
      "INFO:transformers.configuration_utils:Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "INFO:filelock:Lock 8792574288 acquired on /Users/takizawa/.cache/torch/transformers/4801b91bfd2de0a4478e02e4a2404e982bd3d6773bc2935eea468f9c644fb593.fbee186ac33c194356f35147fe415d5392623f762cc279e97cecc31b90238cb3.lock\n",
      "INFO:transformers.file_utils:https://cdn.huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/pytorch_model.bin not found in cache or force_download set to True, downloading to /Users/takizawa/.cache/torch/transformers/tmpm_8ft_19\n",
      "Downloading: 100%|███████████████████████████| 445M/445M [01:16<00:00, 5.85MB/s]\n",
      "INFO:transformers.file_utils:storing https://cdn.huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/pytorch_model.bin in cache at /Users/takizawa/.cache/torch/transformers/4801b91bfd2de0a4478e02e4a2404e982bd3d6773bc2935eea468f9c644fb593.fbee186ac33c194356f35147fe415d5392623f762cc279e97cecc31b90238cb3\n",
      "INFO:transformers.file_utils:creating metadata file for /Users/takizawa/.cache/torch/transformers/4801b91bfd2de0a4478e02e4a2404e982bd3d6773bc2935eea468f9c644fb593.fbee186ac33c194356f35147fe415d5392623f762cc279e97cecc31b90238cb3\n",
      "INFO:filelock:Lock 8792574288 released on /Users/takizawa/.cache/torch/transformers/4801b91bfd2de0a4478e02e4a2404e982bd3d6773bc2935eea468f9c644fb593.fbee186ac33c194356f35147fe415d5392623f762cc279e97cecc31b90238cb3.lock\n",
      "INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking/pytorch_model.bin from cache at /Users/takizawa/.cache/torch/transformers/4801b91bfd2de0a4478e02e4a2404e982bd3d6773bc2935eea468f9c644fb593.fbee186ac33c194356f35147fe415d5392623f762cc279e97cecc31b90238cb3\n",
      "INFO:transformers.modeling_utils:All model checkpoint weights were used when initializing BertEncoder.\n",
      "\n",
      "INFO:transformers.modeling_utils:All the weights of BertEncoder were initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertEncoder for predictions without further training.\n",
      "INFO:root:Define Loss and Optimizer\n",
      "INFO:root:Start Training\n",
      "Epoch: 1:   0%|         | 1/54882 [02:03<1874:58:30, 122.99s/it, Loss: 10.23237]^C\n"
     ]
    }
   ],
   "source": [
    "!python3 main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## これは不要\n",
    "# from google.colab import files\n",
    "# files.download('./data/ckpt.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
